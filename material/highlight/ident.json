{
    "documents": [
        {
            "bookmarks": [
            ],
            "checksum": "716ac9bbbed7e4640e484ae924a34ede",
            "highlights": [
                {
                    "description": "However, a number of ransomware samples possess similarity as they are created by similar groups of threat actors. A particular threat actor or group often adopts similar practices or codebase to create unlimited versions of their ransomware. As a result of these common traits and codebase, it is probable that new or unknown ransomware variants can be detected based on a comparison with their originating or existing samples.",
                    "selection_begin_x": -146,
                    "selection_begin_y": 327,
                    "selection_end_x": -226,
                    "selection_end_y": 400,
                    "type": 111
                },
                {
                    "description": "similarity preserving hashing ",
                    "selection_begin_x": -121,
                    "selection_begin_y": 408,
                    "selection_end_x": -8,
                    "selection_end_y": 411,
                    "type": 115
                },
                {
                    "description": "fuzzy hashing.",
                    "selection_begin_x": -198,
                    "selection_begin_y": 421,
                    "selection_end_x": -147,
                    "selection_end_y": 418,
                    "type": 115
                },
                {
                    "description": "However, a number of ransomware samples possess similarity as they are created by similar groups of threat actors. ",
                    "selection_begin_x": 43,
                    "selection_begin_y": 248,
                    "selection_end_x": 257,
                    "selection_end_y": 265,
                    "type": 111
                },
                {
                    "description": "A particular threat actor or group often adopts some similar practices or codebase to create unlimited versions of their ransomware",
                    "selection_begin_x": 7,
                    "selection_begin_y": 274,
                    "selection_end_x": 50,
                    "selection_end_y": 297,
                    "type": 111
                },
                {
                    "description": "A similarity preserving hashing or fuzzy hashing function has been used for malware analysis in the past,",
                    "selection_begin_x": 260,
                    "selection_begin_y": 369,
                    "selection_end_x": 185,
                    "selection_end_y": 386,
                    "type": 111
                },
                {
                    "description": "which can also be utilised to detect ransomware based on their similarity with other known or existing samples.",
                    "selection_begin_x": 198,
                    "selection_begin_y": 388,
                    "selection_end_x": 170,
                    "selection_end_y": 408,
                    "type": 111
                },
                {
                    "description": "Cryptographic hashing is one of the most popular forms of hashing which can be used to identify a file exclusively (or duplicate flies) to verify its integrity.",
                    "selection_begin_x": -242,
                    "selection_begin_y": 923,
                    "selection_end_x": -87,
                    "selection_end_y": 948,
                    "type": 111
                },
                {
                    "description": "Nonetheless, this hashing cannot be utilised in computer forensics as malware may be of a similar strain, having only changed a binary digit, rendering the file different from the original cryptographically. ",
                    "selection_begin_x": -74,
                    "selection_begin_y": 950,
                    "selection_end_x": -5,
                    "selection_end_y": 988,
                    "type": 111
                },
                {
                    "description": "similarity preserving hash function,",
                    "selection_begin_x": -66,
                    "selection_begin_y": 1008,
                    "selection_end_x": -205,
                    "selection_end_y": 1008,
                    "type": 100
                },
                {
                    "description": "similarity preserving hash function,",
                    "selection_begin_x": -204,
                    "selection_begin_y": 1009,
                    "selection_end_x": -69,
                    "selection_end_y": 1007,
                    "type": 115
                },
                {
                    "description": "determine similarity",
                    "selection_begin_x": -45,
                    "selection_begin_y": 1007,
                    "selection_end_x": -221,
                    "selection_end_y": 1023,
                    "type": 121
                },
                {
                    "description": "In this technique, generally, a file is divided into multiple blocks and a hash value is calculated for each block, finally, all hash values of the blocks are concatenated to generate the fuzzy hash value,",
                    "selection_begin_x": -60,
                    "selection_begin_y": 1081,
                    "selection_end_x": -115,
                    "selection_end_y": 1049,
                    "type": 111
                },
                {
                    "description": "The length of the resulting fuzzy hash value depends on several factors such as the block size, the file size, and the output size of the selected hash function ",
                    "selection_begin_x": -8,
                    "selection_begin_y": 1115,
                    "selection_end_x": -171,
                    "selection_end_y": 1090,
                    "type": 117
                },
                {
                    "description": "This is contrary to the cryptographic hash function, where the complete file is hashed contemporaneously, and the output has fixed size irrespective of the size of the input file.",
                    "selection_begin_x": -38,
                    "selection_begin_y": 1149,
                    "selection_end_x": -237,
                    "selection_end_y": 1129,
                    "type": 111
                },
                {
                    "description": "Fuzzy hashing techniques can be classified into different categories: ",
                    "selection_begin_x": -7,
                    "selection_begin_y": 1165,
                    "selection_end_x": -29,
                    "selection_end_y": 1153,
                    "type": 118
                },
                {
                    "description": "Context-Triggered Piecewise Hashing (CTPH),",
                    "selection_begin_x": -253,
                    "selection_begin_y": 1177,
                    "selection_end_x": -65,
                    "selection_end_y": 1174,
                    "type": 114
                },
                {
                    "description": "StatisticallyImprobable Features (SIF), Block-Based Hashing (BBH) and Block-Based Rebuilding (BBR)",
                    "selection_begin_x": -52,
                    "selection_begin_y": 1175,
                    "selection_end_x": -125,
                    "selection_end_y": 1201,
                    "type": 113
                },
                {
                    "description": "The similarity preserving property of fuzzy hashing is useful in forensic investigations to compare unknown files with known malware families based on their similarity, and to triage and cluster malware which use multiple variants from the same malware family that perform the exact same set of operations, but have different cryptographic hashes",
                    "selection_begin_x": -59,
                    "selection_begin_y": 1200,
                    "selection_end_x": -132,
                    "selection_end_y": 1270,
                    "type": 111
                },
                {
                    "description": "The similarity can be defined either as syntactic similarity or semantic similarity",
                    "selection_begin_x": -248,
                    "selection_begin_y": 1289,
                    "selection_end_x": -170,
                    "selection_end_y": 1293,
                    "type": 111
                },
                {
                    "description": "similarity hashing or fuzzy hashing techniques work on a syntactic level,",
                    "selection_begin_x": -77,
                    "selection_begin_y": 1367,
                    "selection_end_x": -46,
                    "selection_end_y": 1382,
                    "type": 111
                },
                {
                    "description": "The algorithm divides an input file into blocks of variable size, randomly, with the division based on the content of that file",
                    "selection_begin_x": -94,
                    "selection_begin_y": 1434,
                    "selection_end_x": -92,
                    "selection_end_y": 1459,
                    "type": 111
                },
                {
                    "description": "rolling hash ",
                    "selection_begin_x": -53,
                    "selection_begin_y": 1462,
                    "selection_end_x": -7,
                    "selection_end_y": 1464,
                    "type": 115
                },
                {
                    "description": "is used to determine block boundaries (also",
                    "selection_begin_x": -101,
                    "selection_begin_y": 1475,
                    "selection_end_x": -257,
                    "selection_end_y": 1474,
                    "type": 99
                },
                {
                    "description": "(also known as trigger points)",
                    "selection_begin_x": -94,
                    "selection_begin_y": 1473,
                    "selection_end_x": -233,
                    "selection_end_y": 1487,
                    "type": 111
                },
                {
                    "description": "calculates the hash value of each block separately and produces the final SSDEEP hash value by concatenating all the hashes into one hash.",
                    "selection_begin_x": -256,
                    "selection_begin_y": 1519,
                    "selection_end_x": -172,
                    "selection_end_y": 1543,
                    "type": 111
                },
                {
                    "description": "This method ensures that two similar files will have similar block boundaries and similar SSDEEP ",
                    "selection_begin_x": -160,
                    "selection_begin_y": 1544,
                    "selection_end_x": -11,
                    "selection_end_y": 1562,
                    "type": 111
                },
                {
                    "description": "hash values.",
                    "selection_begin_x": 49,
                    "selection_begin_y": 1070,
                    "selection_end_x": 7,
                    "selection_end_y": 1074,
                    "type": 111
                },
                {
                    "description": "calculating the minimum number of operations required to transform one block into the other, using a combination of operations including insertion, deletion, and substitution of a single character, and transpositions of two adjacent characters ",
                    "selection_begin_x": 34,
                    "selection_begin_y": 1107,
                    "selection_end_x": 263,
                    "selection_end_y": 1149,
                    "type": 111
                },
                {
                    "description": "any file consists of several statistical features, ",
                    "selection_begin_x": 72,
                    "selection_begin_y": 1224,
                    "selection_end_x": 248,
                    "selection_end_y": 1226,
                    "type": 111
                },
                {
                    "description": "where some are rare",
                    "selection_begin_x": 7,
                    "selection_begin_y": 1236,
                    "selection_end_x": 86,
                    "selection_end_y": 1240,
                    "type": 114
                },
                {
                    "description": "and some are very common",
                    "selection_begin_x": 202,
                    "selection_begin_y": 1232,
                    "selection_end_x": 57,
                    "selection_end_y": 1245,
                    "type": 114
                },
                {
                    "description": "similar files will probably have the same rare features,",
                    "selection_begin_x": 128,
                    "selection_begin_y": 1245,
                    "selection_end_x": 98,
                    "selection_end_y": 1263,
                    "type": 121
                },
                {
                    "description": "while dissimilar files will probably have different rare features.",
                    "selection_begin_x": 110,
                    "selection_begin_y": 1262,
                    "selection_end_x": 111,
                    "selection_end_y": 1270,
                    "type": 121
                },
                {
                    "description": "The more common rare features, probably the more similar files are.",
                    "selection_begin_x": 124,
                    "selection_begin_y": 1268,
                    "selection_end_x": 146,
                    "selection_end_y": 1282,
                    "type": 101
                },
                {
                    "description": "identifies rare features using an entropy calculation, ",
                    "selection_begin_x": 49,
                    "selection_begin_y": 1305,
                    "selection_end_x": 250,
                    "selection_end_y": 1309,
                    "type": 118
                },
                {
                    "description": "hashing the selected features with the cryptographic hash function SHA-1,",
                    "selection_begin_x": 6,
                    "selection_begin_y": 1317,
                    "selection_end_x": 67,
                    "selection_end_y": 1332,
                    "type": 99
                },
                {
                    "description": "input transformation using the concept of majority votes, encoding of majority votes using the Run-Length Encoding (RLE) approach, and hash generation using a data structure called a Bloom filter",
                    "selection_begin_x": 132,
                    "selection_begin_y": 1481,
                    "selection_end_x": 172,
                    "selection_end_y": 1528,
                    "type": 117
                },
                {
                    "description": "pre-determined neighbourhood is equal to zero, ",
                    "selection_begin_x": 62,
                    "selection_begin_y": 1558,
                    "selection_end_x": 249,
                    "selection_end_y": 1563,
                    "type": 111
                },
                {
                    "description": "In the first stage, the input is transformed into a byte sequence of 0s and 1s based on the majority of votes, where the majority of bits in the",
                    "selection_begin_x": 213,
                    "selection_begin_y": 1518,
                    "selection_end_x": 57,
                    "selection_end_y": 1557,
                    "type": 109
                },
                {
                    "description": "fuzzy hashing method generates a fuzzy hash value of the sample and matches it against the database of fuzzy hashes of known ransomware,",
                    "selection_begin_x": 82,
                    "selection_begin_y": 1998,
                    "selection_end_x": 5,
                    "selection_end_y": 1977,
                    "type": 111
                },
                {
                    "description": "However, the interpretation of the fuzzy hashing result is dependent on the security expert and how efficiently they utilise it for further advanced analysis. ",
                    "selection_begin_x": 123,
                    "selection_begin_y": 2060,
                    "selection_end_x": 241,
                    "selection_end_y": 2090,
                    "type": 98
                },
                {
                    "description": "Fuzzy hashing methods mostly effective on a syntactic level and check structural similarity but do not consider semantic level",
                    "selection_begin_x": 81,
                    "selection_begin_y": 2837,
                    "selection_end_x": 25,
                    "selection_end_y": 2812,
                    "type": 111
                },
                {
                    "description": "Many fuzzy hashing methods (e.g. SSDEEP) are dependent on the block sizes and the overall size of the file for hashes. This can be easily evaded by appending data to the end of the file, in which header and section data are still identical. ",
                    "selection_begin_x": 79,
                    "selection_begin_y": 2905,
                    "selection_end_x": 25,
                    "selection_end_y": 2863,
                    "type": 115
                },
                {
                    "description": "Most fuzzy hashing methods are severely affected by packers and unable to detect similarity in packed files. ",
                    "selection_begin_x": 29,
                    "selection_begin_y": 2953,
                    "selection_end_x": 246,
                    "selection_end_y": 2966,
                    "type": 111
                },
                {
                    "description": "The similarity score generated by any fuzzy hashing method is always diffciult to interpret. ",
                    "selection_begin_x": 181,
                    "selection_begin_y": 2763,
                    "selection_end_x": 26,
                    "selection_end_y": 2750,
                    "type": 111
                },
                {
                    "description": "Any similarity score is intuitively judged by the security expert, which can lead to very different interpretations between security experts. ",
                    "selection_begin_x": 27,
                    "selection_begin_y": 2773,
                    "selection_end_x": 125,
                    "selection_end_y": 2801,
                    "type": 115
                },
                {
                    "description": "Additionally, fuzzy hashing similarity scores can be used further for clustering or classification of samples into similar groups [4].",
                    "selection_begin_x": 191,
                    "selection_begin_y": 432,
                    "selection_end_x": 180,
                    "selection_end_y": 409,
                    "type": 99
                },
                {
                    "description": "Fuzzy hashing is such a function capable of identifying similar files, producing a similarity score expressed as a percentage of their similarity.",
                    "selection_begin_x": -194,
                    "selection_begin_y": 1018,
                    "selection_end_x": -132,
                    "selection_end_y": 1048,
                    "type": 98
                },
                {
                    "description": "does not consider the interpretation of the data,",
                    "selection_begin_x": -103,
                    "selection_begin_y": 1330,
                    "selection_end_x": -41,
                    "selection_end_y": 1322,
                    "type": 103
                },
                {
                    "description": "semantic similarity between the two files can be determined based on the interpretation and context of the data and does not consider the byte structure of the files",
                    "selection_begin_x": -41,
                    "selection_begin_y": 1330,
                    "selection_end_x": -157,
                    "selection_end_y": 1367,
                    "type": 103
                },
                {
                    "description": "storing them in multiple Bloom filters",
                    "selection_begin_x": 80,
                    "selection_begin_y": 1332,
                    "selection_end_x": 223,
                    "selection_end_y": 1333,
                    "type": 115
                },
                {
                    "description": "concatenation of the resulting Bloom filters constitutes the final SDHASH fuzzy hash value.",
                    "selection_begin_x": 146,
                    "selection_begin_y": 1380,
                    "selection_end_x": 25,
                    "selection_end_y": 1404,
                    "type": 111
                }
            ],
            "marks": [
                {
                    "symbol": 47,
                    "y_offset": 410
                },
                {
                    "symbol": 110,
                    "y_offset": 1014
                }
            ],
            "offset_x": -37,
            "offset_y": 1523,
            "path": "/home/nuutti/Courses/kandi/material/ransomware-detection-method.pdf",
            "portals": [
            ],
            "zoom_level": 1
        },
        {
            "bookmarks": [
            ],
            "checksum": "c10187b5680e5b5db91e2ec0a1485fe5",
            "highlights": [
                {
                    "description": "context triggered rolling hash",
                    "selection_begin_x": -73,
                    "selection_begin_y": 480,
                    "selection_end_x": -201,
                    "selection_end_y": 494,
                    "type": 102
                },
                {
                    "description": "traditional hashing algorithm",
                    "selection_begin_x": -105,
                    "selection_begin_y": 493,
                    "selection_end_x": -227,
                    "selection_end_y": 505,
                    "type": 102
                },
                {
                    "description": "identify known files that have had data inserted, modified, or deleted.",
                    "selection_begin_x": -205,
                    "selection_begin_y": 503,
                    "selection_end_x": -169,
                    "selection_end_y": 520,
                    "type": 111
                },
                {
                    "description": "piecewise hashing",
                    "selection_begin_x": -164,
                    "selection_begin_y": 554,
                    "selection_end_x": -94,
                    "selection_end_y": 550,
                    "type": 102
                },
                {
                    "description": "Context Triggered Piecewise Hash (CTPH).",
                    "selection_begin_x": -61,
                    "selection_begin_y": 594,
                    "selection_end_x": -130,
                    "selection_end_y": 607,
                    "type": 111
                },
                {
                    "description": "Such hashes can be used to identify ordered homologous sequences between unknown inputs and known files even if the unknown file is a modified version of the known file.",
                    "selection_begin_x": -119,
                    "selection_begin_y": 608,
                    "selection_end_x": -149,
                    "selection_end_y": 640,
                    "type": 111
                },
                {
                    "description": "To date, forensic examiners have used cryptographic hashing algorithms such as MD5 and SHA-1 for data reduction ",
                    "selection_begin_x": -234,
                    "selection_begin_y": 857,
                    "selection_end_x": -9,
                    "selection_end_y": 876,
                    "type": 111
                },
                {
                    "description": "First, if even a single bit of the input is changed, the output will be radically different. Second, given an input and its hash, it is computationally infeasible to find another input that produces the same hash. ",
                    "selection_begin_x": -247,
                    "selection_begin_y": 933,
                    "selection_end_x": -133,
                    "selection_end_y": 967,
                    "type": 111
                },
                {
                    "description": "If any of the new hash values match the known values, the investigator has almost certainly found the known files (White, 2005).",
                    "selection_begin_x": -202,
                    "selection_begin_y": 1047,
                    "selection_end_x": -182,
                    "selection_end_y": 1072,
                    "type": 109
                },
                {
                    "description": "Malicious users can frustrate this technique, however, by making even a one-bit change to known files",
                    "selection_begin_x": -241,
                    "selection_begin_y": 1170,
                    "selection_end_x": -73,
                    "selection_end_y": 1185,
                    "type": 111
                },
                {
                    "description": "Files with one-bit changes are almost entirely identical and share a large ordered homology.",
                    "selection_begin_x": -235,
                    "selection_begin_y": 1275,
                    "selection_end_x": -129,
                    "selection_end_y": 1290,
                    "type": 111
                },
                {
                    "description": "they have identical sequences of genes in the same order. Similarly, two computer files can have ordered homologous sequences if they have large sequences of identical bits in the same order.",
                    "selection_begin_x": -103,
                    "selection_begin_y": 1306,
                    "selection_end_x": -53,
                    "selection_end_y": 1333,
                    "type": 111
                },
                {
                    "description": "The two files are identical except for a set of insertions, modifications, and deletions of data. ",
                    "selection_begin_x": -41,
                    "selection_begin_y": 1330,
                    "selection_end_x": -168,
                    "selection_end_y": 1354,
                    "type": 110
                },
                {
                    "description": "could not be identified as homologous using algorithms such as MD5.",
                    "selection_begin_x": -86,
                    "selection_begin_y": 1403,
                    "selection_end_x": -53,
                    "selection_end_y": 1411,
                    "type": 111
                },
                {
                    "description": "algorithm to create many checksums for a file instead of just one.",
                    "selection_begin_x": 36,
                    "selection_begin_y": 873,
                    "selection_end_x": 5,
                    "selection_end_y": 863,
                    "type": 107
                },
                {
                    "description": "Although the human eye can detect the similarity between the two, there is currently no automated method to do so. ",
                    "selection_begin_x": -45,
                    "selection_begin_y": 1415,
                    "selection_end_x": -51,
                    "selection_end_y": 1437,
                    "type": 107
                },
                {
                    "description": "Rather than to generate a single hash for the entire file, a hash is generated for many discrete fixed-size segments of the file.",
                    "selection_begin_x": 41,
                    "selection_begin_y": 873,
                    "selection_end_x": 70,
                    "selection_end_y": 904,
                    "type": 111
                },
                {
                    "description": "Piecewise hashing can use either cryptographic hashing algorithms, such as MD5 in dcfdld or more traditional hashing algorithms such as a Fowler/Noll/Vo (FNV) hash.",
                    "selection_begin_x": 19,
                    "selection_begin_y": 990,
                    "selection_end_x": 208,
                    "selection_end_y": 1017,
                    "type": 105
                },
                {
                    "description": "algorithm used to compute the piecewise hashes is called the traditional hash to distinguish it from the rolling hash",
                    "selection_begin_x": 6,
                    "selection_begin_y": 1036,
                    "selection_end_x": 223,
                    "selection_end_y": 1048,
                    "type": 111
                },
                {
                    "description": "A rolling hash algorithm produces a pseudo-random value based only on the current context of the input.",
                    "selection_begin_x": 195,
                    "selection_begin_y": 1121,
                    "selection_end_x": 0,
                    "selection_end_y": 1111,
                    "type": 111
                },
                {
                    "description": "The rolling hash works by maintaining a state based solely on the last few bytes from the input.",
                    "selection_begin_x": 202,
                    "selection_begin_y": 1117,
                    "selection_end_x": 107,
                    "selection_end_y": 1143,
                    "type": 122
                },
                {
                    "description": "Each byte is added to the state as it is processed and removed from the state after a set number of other bytes have been processed. ",
                    "selection_begin_x": 146,
                    "selection_begin_y": 1164,
                    "selection_end_x": 113,
                    "selection_end_y": 1144,
                    "type": 122
                },
                {
                    "description": "At any position p in the input, the state of the rolling hash will depend only on the last s bytes of the file. Thus, the value of the rolling hash, r, can be expressed as a function of the last few bytes as shown in Eq. (1). rp ¼ F � bp; bp�1; bp�2; .; bp�s ",
                    "selection_begin_x": 165,
                    "selection_begin_y": 1199,
                    "selection_end_x": 121,
                    "selection_end_y": 1261,
                    "type": 111
                },
                {
                    "description": "Whereas current piecewise hashing programs such as dcfldd used fixed offsets to determine when to start and stop the traditional hash algorithm, a CTPH algorithm uses the rolling hash.",
                    "selection_begin_x": 26,
                    "selection_begin_y": 1466,
                    "selection_end_x": 8,
                    "selection_end_y": 1431,
                    "type": 111
                },
                {
                    "description": "When the output of the rolling hash produces a specific ",
                    "selection_begin_x": 33,
                    "selection_begin_y": 1465,
                    "selection_end_x": 251,
                    "selection_end_y": 1474,
                    "type": 102
                },
                {
                    "description": "output, or trigger value, the traditional hash is triggered.",
                    "selection_begin_x": -245,
                    "selection_begin_y": 1661,
                    "selection_end_x": -30,
                    "selection_end_y": 1661,
                    "type": 102
                },
                {
                    "description": "That is, while processing the input flie, one begins to compute the traditional hash for the file.",
                    "selection_begin_x": -23,
                    "selection_begin_y": 1651,
                    "selection_end_x": -137,
                    "selection_end_y": 1680,
                    "type": 111
                },
                {
                    "description": "Simultaneously, one must also compute the rolling hash for the file.",
                    "selection_begin_x": -131,
                    "selection_begin_y": 1679,
                    "selection_end_x": -104,
                    "selection_end_y": 1690,
                    "type": 111
                },
                {
                    "description": "When the rolling hash produces a trigger value, the value of the traditional hash is recorded in the CTPH signature and the traditional hash is reset. ",
                    "selection_begin_x": -91,
                    "selection_begin_y": 1692,
                    "selection_end_x": -226,
                    "selection_end_y": 1727,
                    "type": 111
                },
                {
                    "description": "When the rolling hash produces a trigger value, the value of the traditional hash is recorded in the CTPH signature and the traditional hash is reset. ",
                    "selection_begin_x": -95,
                    "selection_begin_y": 1691,
                    "selection_end_x": -224,
                    "selection_end_y": 1724,
                    "type": 121
                },
                {
                    "description": "each recorded value in the CTPH signature depends only on part of the input, and changes to the input will result in only localized changes in the CTPH signature. ",
                    "selection_begin_x": -9,
                    "selection_begin_y": 1763,
                    "selection_end_x": -173,
                    "selection_end_y": 1740,
                    "type": 98
                },
                {
                    "description": "if a byte of the input is changed, at most two, and in many cases, only one of the traditional hash values will be changed;",
                    "selection_begin_x": -189,
                    "selection_begin_y": 1773,
                    "selection_end_x": -186,
                    "selection_end_y": 1798,
                    "type": 113
                },
                {
                    "description": "the majority of the CTPH signature will remain the same.",
                    "selection_begin_x": -178,
                    "selection_begin_y": 1800,
                    "selection_end_x": -189,
                    "selection_end_y": 1812,
                    "type": 115
                },
                {
                    "description": "Because the majority of the signature remains the same, files with modifications can still be associated with the CTPH signatures of known files. ",
                    "selection_begin_x": -181,
                    "selection_begin_y": 1804,
                    "selection_end_x": -109,
                    "selection_end_y": 1830,
                    "type": 104
                },
                {
                    "description": "this paper, the trigger value will be referred to as the block size.",
                    "selection_begin_x": -129,
                    "selection_begin_y": 2140,
                    "selection_end_x": -127,
                    "selection_end_y": 2146,
                    "type": 114
                },
                {
                    "description": "Two constants, a minimum ",
                    "selection_begin_x": -114,
                    "selection_begin_y": 2148,
                    "selection_end_x": -6,
                    "selection_end_y": 2151,
                    "type": 116
                },
                {
                    "description": "block size, bmin, and a spamsum length, S, are used to set the initial block size for an input of n bytes using",
                    "selection_begin_x": 216,
                    "selection_begin_y": 1670,
                    "selection_end_x": 8,
                    "selection_end_y": 1657,
                    "type": 116
                },
                {
                    "description": "processed under certain conditions defnied below. Thus, the block size computed before the input is read is called the initial blocksize,",
                    "selection_begin_x": 229,
                    "selection_begin_y": 1685,
                    "selection_end_x": 44,
                    "selection_end_y": 1714,
                    "type": 98
                },
                {
                    "description": "If the rolling hash produces a value that is equal, modulo the block size, to the block size minus one, the rolling checksum has hit a trigger value.",
                    "selection_begin_x": 245,
                    "selection_begin_y": 1768,
                    "selection_end_x": 93,
                    "selection_end_y": 1806,
                    "type": 107
                },
                {
                    "description": "LS6B",
                    "selection_begin_x": 38,
                    "selection_begin_y": 1814,
                    "selection_end_x": 52,
                    "selection_end_y": 1815,
                    "type": 97
                },
                {
                    "description": "LS6B",
                    "selection_begin_x": 39,
                    "selection_begin_y": 1813,
                    "selection_end_x": 53,
                    "selection_end_y": 1814,
                    "type": 115
                },
                {
                    "description": "traditional hash is appended to the first part of the final signature.",
                    "selection_begin_x": 88,
                    "selection_begin_y": 1814,
                    "selection_end_x": 110,
                    "selection_end_y": 1826,
                    "type": 111
                },
                {
                    "description": "After every byte of the input has been processed, the final signature is examined. If the frist part of the signature is not long enough after all of the input is processed, the block size is halved and the input is processed again. ",
                    "selection_begin_x": 180,
                    "selection_begin_y": 1943,
                    "selection_end_x": 21,
                    "selection_end_y": 1910,
                    "type": 103
                },
                {
                    "description": "The final spamsum signature consists of the block size, the two sets of LS6Bs, and the input’s filename in quotes. The first set of LS6Bs is computed with block size b and the other 2b.",
                    "selection_begin_x": 64,
                    "selection_begin_y": 1985,
                    "selection_end_x": 25,
                    "selection_end_y": 1955,
                    "type": 103
                },
                {
                    "description": "Two spamsum signatures can be compared to determine if files from which they were derived are homologous.",
                    "selection_begin_x": 13,
                    "selection_begin_y": 2084,
                    "selection_end_x": 228,
                    "selection_end_y": 2094,
                    "type": 111
                },
                {
                    "description": "Because the input may need to be processed more than once to compute a CTPH, the running time for CTPH programs may be considerably longer than comparable cryptographic hashing programs.",
                    "selection_begin_x": -245,
                    "selection_begin_y": 3785,
                    "selection_end_x": -140,
                    "selection_end_y": 3820,
                    "type": 111
                },
                {
                    "description": "Note that ssdeep was significantly slower than the cryptographic hashing algorithms",
                    "selection_begin_x": -144,
                    "selection_begin_y": 3878,
                    "selection_end_x": -33,
                    "selection_end_y": 3894,
                    "type": 111
                },
                {
                    "description": "The CTPH technique described in this paper is quite applicable to computer forensics.",
                    "selection_begin_x": 11,
                    "selection_begin_y": 3593,
                    "selection_end_x": 110,
                    "selection_end_y": 3603,
                    "type": 111
                },
                {
                    "description": "CTPH can be used to identify documents that are highly similar but not identical.",
                    "selection_begin_x": 13,
                    "selection_begin_y": 3708,
                    "selection_end_x": 91,
                    "selection_end_y": 3714,
                    "type": 111
                },
                {
                    "description": "The comparison of partial files, especially footers, is significant as it represents a new capability for forensic examiners. A JPEG file, for example, missing its header cannot be displayed under any circumstances. Even",
                    "selection_begin_x": -74,
                    "selection_begin_y": 4473,
                    "selection_end_x": -247,
                    "selection_end_y": 4440,
                    "type": 111
                },
                {
                    "description": "By using CTPH to detect the homology between unviewable partial files and known file, the examiner can develop new leads even from files that cannot be examined conventionally. ",
                    "selection_begin_x": 8,
                    "selection_begin_y": 4140,
                    "selection_end_x": 80,
                    "selection_end_y": 4173,
                    "type": 111
                },
                {
                    "description": "If a change is made in the input file such that none of the contexts that trigger the rolling hash are altered, one of the traditional hash values will still be changed.",
                    "selection_begin_x": -243,
                    "selection_begin_y": 3265,
                    "selection_end_x": -90,
                    "selection_end_y": 3292,
                    "type": 112
                },
                {
                    "description": "If a modification is made in the input file such that one of the context triggers is changed, at most two of the traditional hash values will be changed.",
                    "selection_begin_x": -103,
                    "selection_begin_y": 3441,
                    "selection_end_x": -256,
                    "selection_end_y": 3415,
                    "type": 111
                }
            ],
            "marks": [
                {
                    "symbol": 47,
                    "y_offset": 707
                }
            ],
            "offset_x": 43,
            "offset_y": 3781,
            "path": "/home/nuutti/Courses/kandi/material/identifying-almost-identical-files.pdf",
            "portals": [
            ],
            "zoom_level": 1
        },
        {
            "bookmarks": [
                {
                    "description": "test",
                    "y_offset": 1893
                }
            ],
            "checksum": "fcc68ec49ca40871546e87196eeed38a",
            "highlights": [
            ],
            "marks": [
                {
                    "symbol": 106,
                    "y_offset": 1340
                },
                {
                    "symbol": 107,
                    "y_offset": 1372
                },
                {
                    "symbol": 109,
                    "y_offset": 1340
                }
            ],
            "offset_x": -12,
            "offset_y": 1978,
            "path": "/usr/share/sioyek/tutorial.pdf",
            "portals": [
            ],
            "zoom_level": 2
        }
    ]
}
